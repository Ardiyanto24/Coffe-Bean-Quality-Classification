{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7800e449",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-01-08T02:44:55.678357Z",
     "iopub.status.busy": "2026-01-08T02:44:55.678130Z",
     "iopub.status.idle": "2026-01-08T04:09:06.491233Z",
     "shell.execute_reply": "2026-01-08T04:09:06.490385Z"
    },
    "papermill": {
     "duration": 5050.81771,
     "end_time": "2026-01-08T04:09:06.492782",
     "exception": false,
     "start_time": "2026-01-08T02:44:55.675072",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-08 02:44:57.985947: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1767840298.179243      24 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1767840298.230268      24 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1767840298.655510      24 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1767840298.655551      24 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1767840298.655554      24 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1767840298.655557      24 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "/usr/local/lib/python3.12/dist-packages/sqlalchemy/orm/query.py:195: SyntaxWarning: \"is not\" with 'tuple' literal. Did you mean \"!=\"?\n",
      "  if entities is not ():\n",
      "\u001b[32m[I 2026-01-08 02:45:12,601]\u001b[0m A new study created in memory with name: no-name-485b0e1d-276b-4f4c-8e6f-3438f62fb648\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ART_DIR: /kaggle/input/coffe-bean-classification-preprocessing/artifacts_preprocess\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1767840313.262876      24 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb2_notop.h5\n",
      "\u001b[1m31790344/31790344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1767840353.075998      24 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/EfficientNetB2_Tuned_1/efficientnetb2_1/block1b_drop_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "I0000 00:00:1767840358.372765      63 cuda_dnn.cc:529] Loaded cuDNN version 91002\n",
      "\u001b[32m[I 2026-01-08 02:50:37,684]\u001b[0m Trial 0 finished with value: 0.9839572310447693 and parameters: {'variant': 'B2', 'batch_size': 48, 'lr': 0.00032357184597318195, 'dropout': 0.2269541167803069, 'dense_units': 512, 'l2': 1.319976086082518e-05, 'label_smoothing': 0.10534375574896877, 'freeze_backbone': False, 'fine_tune_at': 120, 'optimizer': 'adamw', 'weight_decay': 2.6462112902335828e-05}. Best is trial 0 with value: 0.9839572310447693.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb1_notop.h5\n",
      "\u001b[1m27018416/27018416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1767840651.454258      24 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/EfficientNetB1_Tuned_1/efficientnetb1_1/block1b_drop_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "\u001b[32m[I 2026-01-08 02:52:25,734]\u001b[0m Trial 1 finished with value: 0.9358288645744324 and parameters: {'variant': 'B1', 'batch_size': 64, 'lr': 0.0006699764747710552, 'dropout': 0.13744983203382383, 'dense_units': 128, 'l2': 4.468618412331749e-06, 'label_smoothing': 0.030769713149501936, 'freeze_backbone': True, 'optimizer': 'adam'}. Best is trial 0 with value: 0.9839572310447693.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb3_notop.h5\n",
      "\u001b[1m43941136/43941136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1767840760.778870      24 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/EfficientNetB3_Tuned_1/efficientnetb3_1/block1b_drop_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "\u001b[32m[I 2026-01-08 02:57:00,029]\u001b[0m Trial 2 finished with value: 0.9625668525695801 and parameters: {'variant': 'B3', 'batch_size': 16, 'lr': 0.000338910009543314, 'dropout': 0.4504831731973134, 'dense_units': 512, 'l2': 0.0007082069840015407, 'label_smoothing': 0.12679685759946216, 'freeze_backbone': True, 'optimizer': 'adamw', 'weight_decay': 4.46237643673059e-05}. Best is trial 0 with value: 0.9839572310447693.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
      "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1767841029.653750      24 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/EfficientNetB0_Tuned_1/efficientnetb0_1/block2b_drop_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "\u001b[32m[I 2026-01-08 02:58:31,287]\u001b[0m Trial 3 finished with value: 0.9358288645744324 and parameters: {'variant': 'B0', 'batch_size': 32, 'lr': 0.00023630038867736522, 'dropout': 0.03782242911029554, 'dense_units': 0, 'l2': 7.530903660381047e-07, 'label_smoothing': 0.13553258490939663, 'freeze_backbone': True, 'optimizer': 'adam'}. Best is trial 0 with value: 0.9839572310447693.\u001b[0m\n",
      "E0000 00:00:1767841148.508367      24 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/EfficientNetB2_Tuned_1/efficientnetb2_1/block1b_drop_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "\u001b[32m[I 2026-01-08 03:05:50,142]\u001b[0m Trial 4 finished with value: 0.9946523904800415 and parameters: {'variant': 'B2', 'batch_size': 16, 'lr': 0.00011590408880027403, 'dropout': 0.4404891892887236, 'dense_units': 512, 'l2': 0.0003115019435199289, 'label_smoothing': 0.08667753759456968, 'freeze_backbone': False, 'fine_tune_at': 120, 'optimizer': 'adamw', 'weight_decay': 3.287233647548358e-06}. Best is trial 4 with value: 0.9946523904800415.\u001b[0m\n",
      "E0000 00:00:1767841601.914884      24 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/EfficientNetB3_Tuned_1/efficientnetb3_1/block1b_drop_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "\u001b[32m[I 2026-01-08 03:07:09,311]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 03:07:59,935]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 19.\u001b[0m\n",
      "E0000 00:00:1767841722.236370      24 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/EfficientNetB1_Tuned_1/efficientnetb1_1/block1b_drop_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "\u001b[32m[I 2026-01-08 03:09:06,752]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "E0000 00:00:1767841785.978472      24 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/EfficientNetB1_Tuned_1/efficientnetb1_1/block1b_drop_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "\u001b[32m[I 2026-01-08 03:10:03,932]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 03:10:19,522]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "E0000 00:00:1767841857.182795      24 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/EfficientNetB2_Tuned_1/efficientnetb2_1/block1b_drop_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "\u001b[32m[I 2026-01-08 03:11:12,302]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 03:12:04,272]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "E0000 00:00:1767841963.201925      24 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/EfficientNetB2_Tuned_1/efficientnetb2_1/block1b_drop_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "\u001b[32m[I 2026-01-08 03:13:09,608]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 2.\u001b[0m\n",
      "E0000 00:00:1767842028.474427      24 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/EfficientNetB2_Tuned_1/efficientnetb2_1/block1b_drop_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "\u001b[32m[I 2026-01-08 03:14:08,426]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 03:15:01,249]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "E0000 00:00:1767842148.202257      24 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/EfficientNetB2_Tuned_1/efficientnetb2_1/block1b_drop_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "\u001b[32m[I 2026-01-08 03:18:55,560]\u001b[0m Trial 15 finished with value: 0.9839572310447693 and parameters: {'variant': 'B2', 'batch_size': 16, 'lr': 0.00015549128592949105, 'dropout': 0.3954037673794965, 'dense_units': 512, 'l2': 3.7003879556438924e-05, 'label_smoothing': 0.1492716213420554, 'freeze_backbone': False, 'fine_tune_at': 50, 'optimizer': 'adamw', 'weight_decay': 5.4995468567929755e-06}. Best is trial 4 with value: 0.9946523904800415.\u001b[0m\n",
      "E0000 00:00:1767842386.847040      24 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/EfficientNetB2_Tuned_1/efficientnetb2_1/block1b_drop_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "\u001b[32m[I 2026-01-08 03:20:07,272]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "E0000 00:00:1767842452.025138      24 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/EfficientNetB2_Tuned_1/efficientnetb2_1/block1b_drop_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "\u001b[32m[I 2026-01-08 03:21:07,197]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "E0000 00:00:1767842513.844696      24 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/EfficientNetB3_Tuned_1/efficientnetb3_1/block1b_drop_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "\u001b[32m[I 2026-01-08 03:25:35,440]\u001b[0m Trial 18 finished with value: 0.9893048405647278 and parameters: {'variant': 'B3', 'batch_size': 16, 'lr': 0.00048560094837439327, 'dropout': 0.4397524445441297, 'dense_units': 0, 'l2': 1.485006077150752e-05, 'label_smoothing': 0.03259963389585704, 'freeze_backbone': False, 'fine_tune_at': 120, 'optimizer': 'adamw', 'weight_decay': 0.00010077988468149744}. Best is trial 4 with value: 0.9946523904800415.\u001b[0m\n",
      "E0000 00:00:1767842782.581422      24 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/EfficientNetB3_Tuned_1/efficientnetb3_1/block1b_drop_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "\u001b[32m[I 2026-01-08 03:32:02,068]\u001b[0m Trial 19 finished with value: 1.0 and parameters: {'variant': 'B3', 'batch_size': 16, 'lr': 0.0008650221856095975, 'dropout': 0.4373578704553349, 'dense_units': 0, 'l2': 0.0001371278630792193, 'label_smoothing': 0.029227182207990365, 'freeze_backbone': False, 'fine_tune_at': 120, 'optimizer': 'adamw', 'weight_decay': 0.00015096859040107197}. Best is trial 19 with value: 1.0.\u001b[0m\n",
      "E0000 00:00:1767843169.179529      24 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/EfficientNetB3_Tuned_1/efficientnetb3_1/block1b_drop_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "\u001b[32m[I 2026-01-08 03:33:44,893]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "E0000 00:00:1767843272.262175      24 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/EfficientNetB3_Tuned_1/efficientnetb3_1/block1b_drop_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "\u001b[32m[I 2026-01-08 03:34:52,558]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "E0000 00:00:1767843340.689512      24 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/EfficientNetB3_Tuned_1/efficientnetb3_1/block1b_drop_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "\u001b[32m[I 2026-01-08 03:39:10,090]\u001b[0m Trial 22 finished with value: 0.9893048405647278 and parameters: {'variant': 'B3', 'batch_size': 16, 'lr': 0.0013049361963344368, 'dropout': 0.43018115168702925, 'dense_units': 0, 'l2': 0.00011284435766381983, 'label_smoothing': 0.023717778699799585, 'freeze_backbone': False, 'fine_tune_at': 120, 'optimizer': 'adamw', 'weight_decay': 0.00010972743457849061}. Best is trial 19 with value: 1.0.\u001b[0m\n",
      "E0000 00:00:1767843599.256190      24 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/EfficientNetB3_Tuned_1/efficientnetb3_1/block1b_drop_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "\u001b[32m[I 2026-01-08 03:40:20,345]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "E0000 00:00:1767843677.781078      24 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/EfficientNetB3_Tuned_1/efficientnetb3_1/block1b_drop_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "\u001b[32m[I 2026-01-08 03:50:21,367]\u001b[0m Trial 24 finished with value: 1.0 and parameters: {'variant': 'B3', 'batch_size': 16, 'lr': 0.0005111156571946818, 'dropout': 0.45756376592993353, 'dense_units': 0, 'l2': 2.1969589750876267e-05, 'label_smoothing': 0.04606201966459476, 'freeze_backbone': False, 'fine_tune_at': 50, 'optimizer': 'adamw', 'weight_decay': 4.5965759194980006e-05}. Best is trial 19 with value: 1.0.\u001b[0m\n",
      "E0000 00:00:1767844279.643881      24 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/EfficientNetB3_Tuned_1/efficientnetb3_1/block1b_drop_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "\u001b[32m[I 2026-01-08 03:51:46,328]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 03:52:18,358]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "E0000 00:00:1767844396.733062      24 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/EfficientNetB3_Tuned_1/efficientnetb3_1/block1b_drop_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "\u001b[32m[I 2026-01-08 03:57:21,570]\u001b[0m Trial 27 finished with value: 0.9893048405647278 and parameters: {'variant': 'B3', 'batch_size': 16, 'lr': 0.0004139644339030403, 'dropout': 0.40853148140278045, 'dense_units': 0, 'l2': 2.349286064139008e-05, 'label_smoothing': 0.06677426260309544, 'freeze_backbone': False, 'fine_tune_at': 50, 'optimizer': 'adamw', 'weight_decay': 5.9564113850147084e-05}. Best is trial 19 with value: 1.0.\u001b[0m\n",
      "E0000 00:00:1767844694.377802      24 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/EfficientNetB1_Tuned_1/efficientnetb1_1/block1b_drop_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "\u001b[32m[I 2026-01-08 03:58:32,210]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 03:59:24,710]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best value: 1.0\n",
      "Best params: {'variant': 'B3', 'batch_size': 16, 'lr': 0.0008650221856095975, 'dropout': 0.4373578704553349, 'dense_units': 0, 'l2': 0.0001371278630792193, 'label_smoothing': 0.029227182207990365, 'freeze_backbone': False, 'fine_tune_at': 120, 'optimizer': 'adamw', 'weight_decay': 0.00015096859040107197}\n",
      "✅ Saved to: /kaggle/working/optuna_effnet_b0_b3\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1767844815.786065      24 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/EfficientNetB3_Tuned_1/efficientnetb3_1/block1b_drop_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 312ms/step - accuracy: 0.6665 - loss: 0.8143 - val_accuracy: 0.9198 - val_loss: 0.2338 - learning_rate: 8.6502e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 227ms/step - accuracy: 0.9116 - loss: 0.2800 - val_accuracy: 0.8663 - val_loss: 0.9702 - learning_rate: 8.6502e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 227ms/step - accuracy: 0.9365 - loss: 0.1940 - val_accuracy: 0.8610 - val_loss: 0.4517 - learning_rate: 8.6502e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 229ms/step - accuracy: 0.9479 - loss: 0.1505 - val_accuracy: 0.9626 - val_loss: 0.0918 - learning_rate: 8.6502e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 227ms/step - accuracy: 0.9850 - loss: 0.0505 - val_accuracy: 0.9679 - val_loss: 0.1416 - learning_rate: 8.6502e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 230ms/step - accuracy: 0.9851 - loss: 0.0492 - val_accuracy: 0.9786 - val_loss: 0.0909 - learning_rate: 8.6502e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 227ms/step - accuracy: 0.9730 - loss: 0.0759 - val_accuracy: 0.9519 - val_loss: 0.2808 - learning_rate: 8.6502e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 227ms/step - accuracy: 0.9891 - loss: 0.0497 - val_accuracy: 0.9679 - val_loss: 0.1493 - learning_rate: 8.6502e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.9749 - loss: 0.0655\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00043251109309494495.\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 226ms/step - accuracy: 0.9747 - loss: 0.0658 - val_accuracy: 0.8556 - val_loss: 0.7685 - learning_rate: 8.6502e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 230ms/step - accuracy: 0.9742 - loss: 0.0625 - val_accuracy: 0.9626 - val_loss: 0.0657 - learning_rate: 4.3251e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 229ms/step - accuracy: 0.9967 - loss: 0.0104 - val_accuracy: 0.9947 - val_loss: 0.0294 - learning_rate: 4.3251e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 226ms/step - accuracy: 0.9920 - loss: 0.0264 - val_accuracy: 0.9786 - val_loss: 0.0467 - learning_rate: 4.3251e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 226ms/step - accuracy: 0.9939 - loss: 0.0275 - val_accuracy: 0.9840 - val_loss: 0.0434 - learning_rate: 4.3251e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 229ms/step - accuracy: 0.9935 - loss: 0.0274 - val_accuracy: 0.9947 - val_loss: 0.0237 - learning_rate: 4.3251e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 227ms/step - accuracy: 0.9988 - loss: 0.0059 - val_accuracy: 0.9840 - val_loss: 0.0368 - learning_rate: 4.3251e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 226ms/step - accuracy: 0.9933 - loss: 0.0095 - val_accuracy: 0.9893 - val_loss: 0.0398 - learning_rate: 4.3251e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.9995 - loss: 0.0047\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.00021625554654747248.\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 227ms/step - accuracy: 0.9995 - loss: 0.0048 - val_accuracy: 0.9840 - val_loss: 0.0311 - learning_rate: 4.3251e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 230ms/step - accuracy: 0.9980 - loss: 0.0064 - val_accuracy: 0.9947 - val_loss: 0.0153 - learning_rate: 2.1626e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 230ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9947 - val_loss: 0.0148 - learning_rate: 2.1626e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 227ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.9840 - val_loss: 0.0176 - learning_rate: 2.1626e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 226ms/step - accuracy: 1.0000 - loss: 7.0912e-04 - val_accuracy: 0.9840 - val_loss: 0.0184 - learning_rate: 2.1626e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 230ms/step - accuracy: 0.9970 - loss: 0.0077 - val_accuracy: 1.0000 - val_loss: 0.0094 - learning_rate: 2.1626e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 227ms/step - accuracy: 0.9974 - loss: 0.0085 - val_accuracy: 0.9893 - val_loss: 0.0295 - learning_rate: 2.1626e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 226ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.9947 - val_loss: 0.0126 - learning_rate: 2.1626e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 1.0000 - loss: 0.0011\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.00010812777327373624.\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 227ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9947 - val_loss: 0.0114 - learning_rate: 2.1626e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 227ms/step - accuracy: 0.9985 - loss: 0.0073 - val_accuracy: 1.0000 - val_loss: 0.0100 - learning_rate: 1.0813e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 227ms/step - accuracy: 0.9994 - loss: 0.0017 - val_accuracy: 0.9947 - val_loss: 0.0112 - learning_rate: 1.0813e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 230ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9947 - val_loss: 0.0087 - learning_rate: 1.0813e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 230ms/step - accuracy: 1.0000 - loss: 9.3953e-04 - val_accuracy: 0.9947 - val_loss: 0.0074 - learning_rate: 1.0813e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 227ms/step - accuracy: 1.0000 - loss: 6.2951e-04 - val_accuracy: 0.9947 - val_loss: 0.0075 - learning_rate: 1.0813e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 230ms/step - accuracy: 1.0000 - loss: 7.9678e-04 - val_accuracy: 1.0000 - val_loss: 0.0069 - learning_rate: 1.0813e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 229ms/step - accuracy: 1.0000 - loss: 8.9106e-04 - val_accuracy: 1.0000 - val_loss: 0.0059 - learning_rate: 1.0813e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 230ms/step - accuracy: 1.0000 - loss: 6.0236e-04 - val_accuracy: 1.0000 - val_loss: 0.0059 - learning_rate: 1.0813e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 226ms/step - accuracy: 1.0000 - loss: 7.4436e-04 - val_accuracy: 1.0000 - val_loss: 0.0069 - learning_rate: 1.0813e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 230ms/step - accuracy: 1.0000 - loss: 5.6673e-04 - val_accuracy: 1.0000 - val_loss: 0.0047 - learning_rate: 1.0813e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 229ms/step - accuracy: 0.9990 - loss: 0.0019 - val_accuracy: 1.0000 - val_loss: 0.0041 - learning_rate: 1.0813e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 226ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 0.0065 - learning_rate: 1.0813e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 227ms/step - accuracy: 1.0000 - loss: 5.3466e-04 - val_accuracy: 1.0000 - val_loss: 0.0087 - learning_rate: 1.0813e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 1.0000 - loss: 5.0617e-04\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 5.406388663686812e-05.\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 227ms/step - accuracy: 1.0000 - loss: 5.0743e-04 - val_accuracy: 1.0000 - val_loss: 0.0084 - learning_rate: 1.0813e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 227ms/step - accuracy: 0.9996 - loss: 0.0014 - val_accuracy: 0.9947 - val_loss: 0.0093 - learning_rate: 5.4064e-05\n",
      "Epoch 41/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 226ms/step - accuracy: 1.0000 - loss: 2.7855e-04 - val_accuracy: 1.0000 - val_loss: 0.0087 - learning_rate: 5.4064e-05\n",
      "Epoch 42/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 1.0000 - loss: 0.0011\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 2.703194331843406e-05.\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 227ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 0.0082 - learning_rate: 5.4064e-05\n",
      "Epoch 43/50\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 226ms/step - accuracy: 1.0000 - loss: 6.5350e-04 - val_accuracy: 0.9947 - val_loss: 0.0091 - learning_rate: 2.7032e-05\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "✅ Saved: /kaggle/working/optuna_effnet_b0_b3/best_model.keras\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# [0] IMPORTS & GLOBAL CONFIG\n",
    "# =========================================\n",
    "import os, json, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import optuna\n",
    "from optuna.pruners import MedianPruner\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "SEED = 42\n",
    "tf.keras.utils.set_random_seed(SEED)\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "\n",
    "EPOCHS = 50\n",
    "NUM_CLASSES = 4\n",
    "CLASS_NAMES = [\"defect\", \"longberry\", \"peaberry\", \"premium\"]\n",
    "\n",
    "# =========================================\n",
    "# [1] FIND PREPROCESSED ARTIFACTS\n",
    "# =========================================\n",
    "CANDIDATE_PATHS = [\n",
    "    Path(\"/kaggle/input/coffe-bean-classification-preprocessing/artifacts_preprocess\"),\n",
    "    Path(\"/kaggle/input/coffee-bean-classification-preprocessing/artifacts_preprocess\"),\n",
    "    Path(\"/kaggle/input/coffe-bean-classification-preprocessing\"),\n",
    "]\n",
    "ART_DIR = None\n",
    "for base in CANDIDATE_PATHS:\n",
    "    if base.exists():\n",
    "        possible_dirs = [base] if (base / \"split_train.csv\").exists() else list(base.rglob(\"artifacts_preprocess\"))\n",
    "        for p in possible_dirs:\n",
    "            if (p / \"split_train.csv\").exists() and (p / \"split_val.csv\").exists():\n",
    "                ART_DIR = p\n",
    "                break\n",
    "    if ART_DIR: break\n",
    "\n",
    "if ART_DIR is None:\n",
    "    input_dir = Path(\"/kaggle/input\")\n",
    "    for dataset_dir in input_dir.iterdir():\n",
    "        if dataset_dir.is_dir():\n",
    "            for p in dataset_dir.rglob(\"artifacts_preprocess\"):\n",
    "                if (p / \"split_train.csv\").exists() and (p / \"split_val.csv\").exists():\n",
    "                    ART_DIR = p\n",
    "                    break\n",
    "        if ART_DIR: break\n",
    "\n",
    "if ART_DIR is None:\n",
    "    raise FileNotFoundError(\"Tidak menemukan artifacts_preprocess\")\n",
    "\n",
    "print(\"✅ ART_DIR:\", ART_DIR)\n",
    "\n",
    "# =========================================\n",
    "# [2] LOAD DATAFRAMES\n",
    "# =========================================\n",
    "train_df = pd.read_csv(ART_DIR / \"split_train.csv\")\n",
    "val_df   = pd.read_csv(ART_DIR / \"split_val.csv\")\n",
    "\n",
    "# =========================================\n",
    "# [3] TF.DATA PIPELINE\n",
    "# =========================================\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "def decode_and_resize(image_path, label, target_size):\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, target_size, method=\"bilinear\")\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    return img, label\n",
    "\n",
    "def create_dataset(df, target_size, training=True, batch_size=32):\n",
    "    paths = df[\"filepath\"].values\n",
    "    labels = df[\"class_name\"].map({c:i for i,c in enumerate(CLASS_NAMES)}).values.astype(np.int32)\n",
    "    ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "    if training:\n",
    "        ds = ds.shuffle(buffer_size=len(df), seed=SEED, reshuffle_each_iteration=True)\n",
    "    ds = ds.map(lambda p,l: decode_and_resize(p,l,target_size), num_parallel_calls=AUTOTUNE)\n",
    "    ds = ds.batch(batch_size).prefetch(AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "# =========================================\n",
    "# [4] MODEL BUILDER: EfficientNet (TUNABLE)\n",
    "# =========================================\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "\n",
    "EFFNET_IMG_SIZES = {\"B0\": (224,224), \"B1\": (240,240), \"B2\": (260,260), \"B3\": (300,300)}\n",
    "EFFNET_FNS = {\n",
    "    \"B0\": tf.keras.applications.EfficientNetB0,\n",
    "    \"B1\": tf.keras.applications.EfficientNetB1,\n",
    "    \"B2\": tf.keras.applications.EfficientNetB2,\n",
    "    \"B3\": tf.keras.applications.EfficientNetB3,\n",
    "}\n",
    "\n",
    "def build_effnet_tunable(\n",
    "    variant=\"B0\",\n",
    "    dense_units=0,\n",
    "    dropout=0.2,\n",
    "    l2=0.0,\n",
    "    freeze_backbone=True,\n",
    "    fine_tune_at=None\n",
    "):\n",
    "    img_size = EFFNET_IMG_SIZES[variant]\n",
    "    base = EFFNET_FNS[variant](\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "        input_shape=(*img_size, 3)\n",
    "    )\n",
    "\n",
    "    if freeze_backbone:\n",
    "        base.trainable = False\n",
    "    else:\n",
    "        base.trainable = True\n",
    "        if fine_tune_at is not None:\n",
    "            for layer in base.layers[:fine_tune_at]:\n",
    "                layer.trainable = False\n",
    "\n",
    "    inputs = layers.Input(shape=(*img_size, 3))\n",
    "    x = tf.keras.applications.efficientnet.preprocess_input(inputs)\n",
    "    x = base(x, training=False)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "    if dense_units and dense_units > 0:\n",
    "        x = layers.Dense(\n",
    "            dense_units,\n",
    "            activation=\"relu\",\n",
    "            kernel_regularizer=regularizers.l2(l2) if l2 > 0 else None\n",
    "        )(x)\n",
    "\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    outputs = layers.Dense(NUM_CLASSES, activation=\"softmax\")(x)\n",
    "    return models.Model(inputs, outputs, name=f\"EfficientNet{variant}_Tuned\")\n",
    "\n",
    "# =========================================\n",
    "# [5] OPTUNA OBJECTIVE\n",
    "# =========================================\n",
    "def objective(trial: optuna.Trial):\n",
    "    variant = trial.suggest_categorical(\"variant\", [\"B0\",\"B1\",\"B2\",\"B3\"])\n",
    "    img_size = EFFNET_IMG_SIZES[variant]\n",
    "\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 48, 64])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 3e-3, log=True)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.0, 0.5)\n",
    "    dense_units = trial.suggest_categorical(\"dense_units\", [0, 128, 256, 512])\n",
    "    l2 = trial.suggest_float(\"l2\", 1e-7, 1e-3, log=True)\n",
    "    label_smoothing = trial.suggest_float(\"label_smoothing\", 0.0, 0.15)\n",
    "\n",
    "    freeze_backbone = trial.suggest_categorical(\"freeze_backbone\", [True, False])\n",
    "    fine_tune_at = None\n",
    "    if not freeze_backbone:\n",
    "        # layer count tiap variant beda; pilih opsi aman\n",
    "        fine_tune_at = trial.suggest_categorical(\"fine_tune_at\", [20, 50, 80, 120])\n",
    "\n",
    "    ds_train = create_dataset(train_df, target_size=img_size, training=True, batch_size=batch_size)\n",
    "    ds_val   = create_dataset(val_df,   target_size=img_size, training=False, batch_size=batch_size)\n",
    "\n",
    "    model = build_effnet_tunable(\n",
    "        variant=variant,\n",
    "        dense_units=dense_units,\n",
    "        dropout=dropout,\n",
    "        l2=l2,\n",
    "        freeze_backbone=freeze_backbone,\n",
    "        fine_tune_at=fine_tune_at\n",
    "    )\n",
    "\n",
    "    opt_name = trial.suggest_categorical(\"optimizer\", [\"adam\", \"adamw\"])\n",
    "    if opt_name == \"adamw\":\n",
    "        try:\n",
    "            opt = tf.keras.optimizers.AdamW(\n",
    "                learning_rate=lr,\n",
    "                weight_decay=trial.suggest_float(\"weight_decay\", 1e-6, 1e-3, log=True)\n",
    "            )\n",
    "        except Exception:\n",
    "            opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    else:\n",
    "        opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "    model.compile(optimizer=opt, loss=loss_fn, metrics=[\"accuracy\"])\n",
    "\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=7, restore_best_weights=True, verbose=0),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, min_lr=1e-7, verbose=0),\n",
    "        optuna.integration.TFKerasPruningCallback(trial, monitor=\"val_accuracy\"),\n",
    "    ]\n",
    "\n",
    "    history = model.fit(ds_train, validation_data=ds_val, epochs=EPOCHS, callbacks=callbacks, verbose=0)\n",
    "    return float(np.max(history.history[\"val_accuracy\"]))\n",
    "\n",
    "# =========================================\n",
    "# [6] RUN STUDY\n",
    "# =========================================\n",
    "study = optuna.create_study(direction=\"maximize\", pruner=MedianPruner(n_startup_trials=5))\n",
    "study.optimize(objective, n_trials=30, gc_after_trial=True)  # sesuaikan\n",
    "\n",
    "print(\"Best value:\", study.best_value)\n",
    "print(\"Best params:\", study.best_params)\n",
    "\n",
    "OUTDIR = Path(\"/kaggle/working/optuna_effnet_b0_b3\")\n",
    "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "pd.DataFrame(study.trials_dataframe()).to_csv(OUTDIR/\"trials.csv\", index=False)\n",
    "with open(OUTDIR/\"best_params.json\", \"w\") as f:\n",
    "    json.dump(study.best_params, f, indent=2)\n",
    "\n",
    "print(\"✅ Saved to:\", OUTDIR)\n",
    "\n",
    "# =========================================\n",
    "# [7] RETRAIN BEST + SAVE MODEL\n",
    "# =========================================\n",
    "best = study.best_params\n",
    "variant = best[\"variant\"]\n",
    "img_size = EFFNET_IMG_SIZES[variant]\n",
    "bs = best[\"batch_size\"]\n",
    "\n",
    "ds_train = create_dataset(train_df, target_size=img_size, training=True, batch_size=bs)\n",
    "ds_val   = create_dataset(val_df,   target_size=img_size, training=False, batch_size=bs)\n",
    "\n",
    "model = build_effnet_tunable(\n",
    "    variant=variant,\n",
    "    dense_units=best[\"dense_units\"],\n",
    "    dropout=best[\"dropout\"],\n",
    "    l2=best[\"l2\"],\n",
    "    freeze_backbone=best[\"freeze_backbone\"],\n",
    "    fine_tune_at=best.get(\"fine_tune_at\", None)\n",
    ")\n",
    "\n",
    "if best[\"optimizer\"] == \"adamw\":\n",
    "    try:\n",
    "        opt = tf.keras.optimizers.AdamW(learning_rate=best[\"lr\"], weight_decay=best.get(\"weight_decay\", 1e-5))\n",
    "    except Exception:\n",
    "        opt = tf.keras.optimizers.Adam(learning_rate=best[\"lr\"])\n",
    "else:\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=best[\"lr\"])\n",
    "\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "model.compile(optimizer=opt, loss=loss_fn, metrics=[\"accuracy\"])\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=7, restore_best_weights=True, verbose=1),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, min_lr=1e-7, verbose=1),\n",
    "]\n",
    "\n",
    "history = model.fit(ds_train, validation_data=ds_val, epochs=EPOCHS, callbacks=callbacks, verbose=1)\n",
    "\n",
    "model.save(OUTDIR/\"best_model.keras\")\n",
    "print(\"✅ Saved:\", OUTDIR/\"best_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9c8b0b",
   "metadata": {
    "papermill": {
     "duration": 0.092243,
     "end_time": "2026-01-08T04:09:06.756920",
     "exception": false,
     "start_time": "2026-01-08T04:09:06.664677",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8902125,
     "sourceId": 13964761,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 290290247,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 290473834,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5057.073235,
   "end_time": "2026-01-08T04:09:10.265954",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-08T02:44:53.192719",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
