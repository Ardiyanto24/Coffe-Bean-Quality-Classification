{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55ed1f9b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-01-08T02:50:52.379525Z",
     "iopub.status.busy": "2026-01-08T02:50:52.379244Z",
     "iopub.status.idle": "2026-01-08T03:02:43.589892Z",
     "shell.execute_reply": "2026-01-08T03:02:43.588931Z"
    },
    "papermill": {
     "duration": 711.216485,
     "end_time": "2026-01-08T03:02:43.591788",
     "exception": false,
     "start_time": "2026-01-08T02:50:52.375303",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna-integration[tfkeras]\r\n",
      "  Downloading optuna_integration-4.6.0-py3-none-any.whl.metadata (12 kB)\r\n",
      "Requirement already satisfied: optuna in /usr/local/lib/python3.12/dist-packages (from optuna-integration[tfkeras]) (2.10.1)\r\n",
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (from optuna-integration[tfkeras]) (2.19.0)\r\n",
      "Requirement already satisfied: alembic in /usr/local/lib/python3.12/dist-packages (from optuna->optuna-integration[tfkeras]) (1.4.3)\r\n",
      "Requirement already satisfied: cliff in /usr/local/lib/python3.12/dist-packages (from optuna->optuna-integration[tfkeras]) (4.13.0)\r\n",
      "Requirement already satisfied: cmaes>=0.8.2 in /usr/local/lib/python3.12/dist-packages (from optuna->optuna-integration[tfkeras]) (0.12.0)\r\n",
      "Requirement already satisfied: colorlog in /usr/local/lib/python3.12/dist-packages (from optuna->optuna-integration[tfkeras]) (6.10.1)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from optuna->optuna-integration[tfkeras]) (2.0.2)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna->optuna-integration[tfkeras]) (25.0)\r\n",
      "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.12/dist-packages (from optuna->optuna-integration[tfkeras]) (1.15.3)\r\n",
      "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from optuna->optuna-integration[tfkeras]) (1.2.19)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna->optuna-integration[tfkeras]) (4.67.1)\r\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna->optuna-integration[tfkeras]) (6.0.3)\r\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->optuna-integration[tfkeras]) (1.4.0)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->optuna-integration[tfkeras]) (1.6.3)\r\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow->optuna-integration[tfkeras]) (25.9.23)\r\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow->optuna-integration[tfkeras]) (0.6.0)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow->optuna-integration[tfkeras]) (0.2.0)\r\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->optuna-integration[tfkeras]) (18.1.1)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow->optuna-integration[tfkeras]) (3.4.0)\r\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow->optuna-integration[tfkeras]) (5.29.5)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->optuna-integration[tfkeras]) (2.32.5)\r\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow->optuna-integration[tfkeras]) (75.2.0)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->optuna-integration[tfkeras]) (1.17.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->optuna-integration[tfkeras]) (3.1.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow->optuna-integration[tfkeras]) (4.15.0)\r\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->optuna-integration[tfkeras]) (2.0.0)\r\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow->optuna-integration[tfkeras]) (1.75.1)\r\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->optuna-integration[tfkeras]) (2.19.0)\r\n",
      "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->optuna-integration[tfkeras]) (3.10.0)\r\n",
      "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->optuna-integration[tfkeras]) (3.15.1)\r\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow->optuna-integration[tfkeras]) (0.5.3)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow->optuna-integration[tfkeras]) (0.45.1)\r\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow->optuna-integration[tfkeras]) (14.2.0)\r\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow->optuna-integration[tfkeras]) (0.1.0)\r\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow->optuna-integration[tfkeras]) (0.17.0)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow->optuna-integration[tfkeras]) (3.4.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow->optuna-integration[tfkeras]) (3.11)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow->optuna-integration[tfkeras]) (2.6.2)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow->optuna-integration[tfkeras]) (2025.11.12)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow->optuna-integration[tfkeras]) (3.9)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow->optuna-integration[tfkeras]) (0.7.2)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow->optuna-integration[tfkeras]) (3.1.3)\r\n",
      "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic->optuna->optuna-integration[tfkeras]) (1.3.10)\r\n",
      "Requirement already satisfied: python-editor>=0.3 in /usr/local/lib/python3.12/dist-packages (from alembic->optuna->optuna-integration[tfkeras]) (1.0.4)\r\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from alembic->optuna->optuna-integration[tfkeras]) (2.9.0.post0)\r\n",
      "Requirement already satisfied: autopage>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from cliff->optuna->optuna-integration[tfkeras]) (0.5.2)\r\n",
      "Requirement already satisfied: cmd2>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from cliff->optuna->optuna-integration[tfkeras]) (2.7.0)\r\n",
      "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.12/dist-packages (from cliff->optuna->optuna-integration[tfkeras]) (3.16.0)\r\n",
      "Requirement already satisfied: stevedore>=5.6.0 in /usr/local/lib/python3.12/dist-packages (from cliff->optuna->optuna-integration[tfkeras]) (5.6.0)\r\n",
      "Requirement already satisfied: pyperclip>=1.8 in /usr/local/lib/python3.12/dist-packages (from cmd2>=1.0.0->cliff->optuna->optuna-integration[tfkeras]) (1.11.0)\r\n",
      "Requirement already satisfied: rich-argparse>=1.7.1 in /usr/local/lib/python3.12/dist-packages (from cmd2>=1.0.0->cliff->optuna->optuna-integration[tfkeras]) (1.7.2)\r\n",
      "Requirement already satisfied: wcwidth>=0.2.10 in /usr/local/lib/python3.12/dist-packages (from cmd2>=1.0.0->cliff->optuna->optuna-integration[tfkeras]) (0.2.14)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow->optuna-integration[tfkeras]) (3.0.3)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow->optuna-integration[tfkeras]) (4.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow->optuna-integration[tfkeras]) (2.19.2)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow->optuna-integration[tfkeras]) (0.1.2)\r\n",
      "Downloading optuna_integration-4.6.0-py3-none-any.whl (99 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: optuna-integration\r\n",
      "Successfully installed optuna-integration-4.6.0\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-08 02:51:00.756153: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1767840660.981633      24 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1767840661.048574      24 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1767840661.592436      24 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1767840661.592493      24 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1767840661.592496      24 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1767840661.592499      24 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "/usr/local/lib/python3.12/dist-packages/sqlalchemy/orm/query.py:195: SyntaxWarning: \"is not\" with 'tuple' literal. Did you mean \"!=\"?\n",
      "  if entities is not ():\n",
      "\u001b[32m[I 2026-01-08 02:51:19,113]\u001b[0m A new study created in memory with name: no-name-7088b39e-2ef3-4ed0-8012-4303701788e0\u001b[0m\n",
      "I0000 00:00:1767840679.889184      24 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1767840695.920659      72 cuda_dnn.cc:529] Loaded cuDNN version 91002\n",
      "\u001b[32m[I 2026-01-08 02:52:58,290]\u001b[0m Trial 0 finished with value: 0.7807486653327942 and parameters: {'batch_size': 64, 'lr': 2.653358431419563e-05, 'dropout': 0.0948638495815744, 'dense_units': 128, 'l2': 0.000888902791659179, 'label_smoothing': 0.05903953394380319, 'freeze_backbone': False, 'fine_tune_at': 120, 'optimizer': 'adam'}. Best is trial 0 with value: 0.7807486653327942.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:53:50,637]\u001b[0m Trial 1 finished with value: 0.8770053386688232 and parameters: {'batch_size': 48, 'lr': 0.0005357543105373378, 'dropout': 0.27355411004194424, 'dense_units': 128, 'l2': 6.34463647226211e-07, 'label_smoothing': 0.08032740794328211, 'freeze_backbone': True, 'optimizer': 'adam'}. Best is trial 1 with value: 0.8770053386688232.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:54:29,037]\u001b[0m Trial 2 finished with value: 0.8770053386688232 and parameters: {'batch_size': 48, 'lr': 0.000661772731042354, 'dropout': 0.09170794962309503, 'dense_units': 256, 'l2': 5.918435079101551e-05, 'label_smoothing': 0.0954772607595231, 'freeze_backbone': True, 'optimizer': 'adamw', 'weight_decay': 1.5159231574691548e-05}. Best is trial 1 with value: 0.8770053386688232.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:55:22,550]\u001b[0m Trial 3 finished with value: 0.7272727489471436 and parameters: {'batch_size': 32, 'lr': 0.00012266150772429415, 'dropout': 0.2241283254975071, 'dense_units': 64, 'l2': 0.0005332238935756903, 'label_smoothing': 0.10234069404254043, 'freeze_backbone': False, 'fine_tune_at': 60, 'optimizer': 'adamw', 'weight_decay': 0.0004526432771813191}. Best is trial 1 with value: 0.8770053386688232.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:55:56,277]\u001b[0m Trial 4 finished with value: 0.893048107624054 and parameters: {'batch_size': 48, 'lr': 0.0019386353936217573, 'dropout': 0.4484700674880492, 'dense_units': 256, 'l2': 1.081259088132334e-06, 'label_smoothing': 0.14823984192097872, 'freeze_backbone': True, 'optimizer': 'adamw', 'weight_decay': 4.753397609007682e-06}. Best is trial 4 with value: 0.893048107624054.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:56:05,921]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:56:15,815]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:56:38,461]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:57:11,410]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:57:27,326]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:57:39,331]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:57:58,582]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 7.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:58:32,450]\u001b[0m Trial 12 finished with value: 0.893048107624054 and parameters: {'batch_size': 48, 'lr': 0.0012598838954852548, 'dropout': 0.3328480207465597, 'dense_units': 256, 'l2': 5.954648448212603e-07, 'label_smoothing': 0.14874491900872044, 'freeze_backbone': True, 'optimizer': 'adam'}. Best is trial 4 with value: 0.893048107624054.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:58:53,561]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 6.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:59:26,248]\u001b[0m Trial 14 finished with value: 0.8877005577087402 and parameters: {'batch_size': 48, 'lr': 0.001459559392785003, 'dropout': 0.47947712263518, 'dense_units': 256, 'l2': 4.237588788223123e-07, 'label_smoothing': 0.1258720683118453, 'freeze_backbone': True, 'optimizer': 'adamw', 'weight_decay': 5.468277070489162e-06}. Best is trial 4 with value: 0.893048107624054.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:59:36,556]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 03:00:13,084]\u001b[0m Trial 16 finished with value: 0.903743326663971 and parameters: {'batch_size': 48, 'lr': 0.001134077259790631, 'dropout': 0.3019440423910115, 'dense_units': 256, 'l2': 2.534372517587611e-06, 'label_smoothing': 0.1270763096398634, 'freeze_backbone': True, 'optimizer': 'adam'}. Best is trial 16 with value: 0.903743326663971.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 03:00:23,457]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 03:00:34,168]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 03:00:44,142]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 03:00:55,951]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 03:01:11,390]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 4.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 03:01:45,577]\u001b[0m Trial 22 finished with value: 0.8823529481887817 and parameters: {'batch_size': 48, 'lr': 0.001461507655677654, 'dropout': 0.29707706302889403, 'dense_units': 256, 'l2': 2.984853467622811e-07, 'label_smoothing': 0.13513001226977334, 'freeze_backbone': True, 'optimizer': 'adam'}. Best is trial 16 with value: 0.903743326663971.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 03:01:55,947]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 03:02:07,737]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best value: 0.903743326663971\n",
      "Best params: {'batch_size': 48, 'lr': 0.001134077259790631, 'dropout': 0.3019440423910115, 'dense_units': 256, 'l2': 2.534372517587611e-06, 'label_smoothing': 0.1270763096398634, 'freeze_backbone': True, 'optimizer': 'adam'}\n",
      "Epoch 1/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 180ms/step - accuracy: 0.4201 - loss: 1.5413 - val_accuracy: 0.7540 - val_loss: 0.6057 - learning_rate: 0.0011\n",
      "Epoch 2/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.7507 - loss: 0.6581 - val_accuracy: 0.8235 - val_loss: 0.4966 - learning_rate: 0.0011\n",
      "Epoch 3/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.8299 - loss: 0.4999 - val_accuracy: 0.8128 - val_loss: 0.4969 - learning_rate: 0.0011\n",
      "Epoch 4/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.8177 - loss: 0.4625 - val_accuracy: 0.8449 - val_loss: 0.4293 - learning_rate: 0.0011\n",
      "Epoch 5/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.8742 - loss: 0.3688 - val_accuracy: 0.8663 - val_loss: 0.3626 - learning_rate: 0.0011\n",
      "Epoch 6/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.9015 - loss: 0.2715 - val_accuracy: 0.8663 - val_loss: 0.3703 - learning_rate: 0.0011\n",
      "Epoch 7/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.9158 - loss: 0.2523 - val_accuracy: 0.8556 - val_loss: 0.3735 - learning_rate: 0.0011\n",
      "Epoch 8/50\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9503 - loss: 0.1928\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005670386017300189.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9493 - loss: 0.1931 - val_accuracy: 0.8824 - val_loss: 0.3731 - learning_rate: 0.0011\n",
      "Epoch 9/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9130 - loss: 0.2360 - val_accuracy: 0.8930 - val_loss: 0.3384 - learning_rate: 5.6704e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9602 - loss: 0.1502 - val_accuracy: 0.8717 - val_loss: 0.3270 - learning_rate: 5.6704e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.9671 - loss: 0.1266 - val_accuracy: 0.8503 - val_loss: 0.3461 - learning_rate: 5.6704e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9668 - loss: 0.1302 - val_accuracy: 0.8717 - val_loss: 0.3181 - learning_rate: 5.6704e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9792 - loss: 0.1144 - val_accuracy: 0.8824 - val_loss: 0.3177 - learning_rate: 5.6704e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.9608 - loss: 0.1286 - val_accuracy: 0.8770 - val_loss: 0.3212 - learning_rate: 5.6704e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.9813 - loss: 0.0973 - val_accuracy: 0.8717 - val_loss: 0.3227 - learning_rate: 5.6704e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9898 - loss: 0.0920\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0002835193008650094.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.9892 - loss: 0.0930 - val_accuracy: 0.8717 - val_loss: 0.3392 - learning_rate: 5.6704e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.9775 - loss: 0.0998 - val_accuracy: 0.8663 - val_loss: 0.3214 - learning_rate: 2.8352e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.9933 - loss: 0.0610 - val_accuracy: 0.8770 - val_loss: 0.3339 - learning_rate: 2.8352e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9920 - loss: 0.0664\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0001417596504325047.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.9919 - loss: 0.0670 - val_accuracy: 0.8717 - val_loss: 0.3193 - learning_rate: 2.8352e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.9911 - loss: 0.0692 - val_accuracy: 0.8877 - val_loss: 0.3334 - learning_rate: 1.4176e-04\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "✅ Saved: /kaggle/working/optuna_mobilenetv2/best_model.keras\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# [0] IMPORTS & GLOBAL CONFIG\n",
    "# =========================================\n",
    "!pip install optuna-integration[tfkeras]\n",
    "\n",
    "import os, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import optuna\n",
    "from optuna.pruners import MedianPruner\n",
    "from pathlib import Path\n",
    "\n",
    "SEED = 42\n",
    "tf.keras.utils.set_random_seed(SEED)\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "\n",
    "EPOCHS = 50\n",
    "NUM_CLASSES = 4\n",
    "CLASS_NAMES = [\"defect\", \"longberry\", \"peaberry\", \"premium\"]\n",
    "IMG_SIZE = (224,224)\n",
    "\n",
    "# =========================================\n",
    "# [1] FIND PREPROCESSED ARTIFACTS\n",
    "# =========================================\n",
    "CANDIDATE_PATHS = [\n",
    "    Path(\"/kaggle/input/coffe-bean-classification-preprocessing/artifacts_preprocess\"),\n",
    "    Path(\"/kaggle/input/coffee-bean-classification-preprocessing/artifacts_preprocess\"),\n",
    "    Path(\"/kaggle/input/coffe-bean-classification-preprocessing\"),\n",
    "]\n",
    "ART_DIR = None\n",
    "for base in CANDIDATE_PATHS:\n",
    "    if base.exists():\n",
    "        possible_dirs = [base] if (base / \"split_train.csv\").exists() else list(base.rglob(\"artifacts_preprocess\"))\n",
    "        for p in possible_dirs:\n",
    "            if (p / \"split_train.csv\").exists() and (p / \"split_val.csv\").exists():\n",
    "                ART_DIR = p\n",
    "                break\n",
    "    if ART_DIR: break\n",
    "if ART_DIR is None:\n",
    "    input_dir = Path(\"/kaggle/input\")\n",
    "    for dataset_dir in input_dir.iterdir():\n",
    "        if dataset_dir.is_dir():\n",
    "            for p in dataset_dir.rglob(\"artifacts_preprocess\"):\n",
    "                if (p / \"split_train.csv\").exists() and (p / \"split_val.csv\").exists():\n",
    "                    ART_DIR = p\n",
    "                    break\n",
    "        if ART_DIR: break\n",
    "if ART_DIR is None:\n",
    "    raise FileNotFoundError(\"Tidak menemukan artifacts_preprocess\")\n",
    "\n",
    "train_df = pd.read_csv(ART_DIR / \"split_train.csv\")\n",
    "val_df   = pd.read_csv(ART_DIR / \"split_val.csv\")\n",
    "\n",
    "# =========================================\n",
    "# [2] TF.DATA PIPELINE\n",
    "# =========================================\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "def decode_and_resize(image_path, label, target_size):\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, target_size, method=\"bilinear\")\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    return img, label\n",
    "\n",
    "def create_dataset(df, target_size, training=True, batch_size=32):\n",
    "    paths = df[\"filepath\"].values\n",
    "    labels = df[\"class_name\"].map({c:i for i,c in enumerate(CLASS_NAMES)}).values.astype(np.int32)\n",
    "    ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "    if training:\n",
    "        ds = ds.shuffle(buffer_size=len(df), seed=SEED, reshuffle_each_iteration=True)\n",
    "    ds = ds.map(lambda p,l: decode_and_resize(p,l,target_size), num_parallel_calls=AUTOTUNE)\n",
    "    ds = ds.batch(batch_size).prefetch(AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "# =========================================\n",
    "# [3] MODEL BUILDER: MobileNetV2 Tunable\n",
    "# =========================================\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "\n",
    "def build_mobilenetv2_tunable(\n",
    "    dense_units=0,\n",
    "    dropout=0.2,\n",
    "    l2=0.0,\n",
    "    freeze_backbone=True,\n",
    "    fine_tune_at=None\n",
    "):\n",
    "    base = tf.keras.applications.MobileNetV2(\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "        input_shape=(224,224,3)\n",
    "    )\n",
    "\n",
    "    if freeze_backbone:\n",
    "        base.trainable = False\n",
    "    else:\n",
    "        base.trainable = True\n",
    "        if fine_tune_at is not None:\n",
    "            for layer in base.layers[:fine_tune_at]:\n",
    "                layer.trainable = False\n",
    "\n",
    "    inputs = layers.Input(shape=(224,224,3))\n",
    "    x = tf.keras.applications.mobilenet_v2.preprocess_input(inputs)\n",
    "    x = base(x, training=False)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "    if dense_units and dense_units > 0:\n",
    "        x = layers.Dense(\n",
    "            dense_units,\n",
    "            activation=\"relu\",\n",
    "            kernel_regularizer=regularizers.l2(l2) if l2 > 0 else None\n",
    "        )(x)\n",
    "\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    outputs = layers.Dense(NUM_CLASSES, activation=\"softmax\")(x)\n",
    "    return models.Model(inputs, outputs, name=\"MobileNetV2_Tuned\")\n",
    "\n",
    "# =========================================\n",
    "# [4] OPTUNA OBJECTIVE\n",
    "# =========================================\n",
    "def objective(trial: optuna.Trial):\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 48, 64])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 3e-3, log=True)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.0, 0.5)\n",
    "    dense_units = trial.suggest_categorical(\"dense_units\", [0, 64, 128, 256])\n",
    "    l2 = trial.suggest_float(\"l2\", 1e-7, 1e-3, log=True)\n",
    "    label_smoothing = trial.suggest_float(\"label_smoothing\", 0.0, 0.15)\n",
    "\n",
    "    freeze_backbone = trial.suggest_categorical(\"freeze_backbone\", [True, False])\n",
    "    fine_tune_at = None\n",
    "    if not freeze_backbone:\n",
    "        # MobileNetV2 layers ~155\n",
    "        fine_tune_at = trial.suggest_categorical(\"fine_tune_at\", [30, 60, 90, 120])\n",
    "\n",
    "    ds_train = create_dataset(train_df, target_size=IMG_SIZE, training=True, batch_size=batch_size)\n",
    "    ds_val   = create_dataset(val_df,   target_size=IMG_SIZE, training=False, batch_size=batch_size)\n",
    "\n",
    "    model = build_mobilenetv2_tunable(\n",
    "        dense_units=dense_units,\n",
    "        dropout=dropout,\n",
    "        l2=l2,\n",
    "        freeze_backbone=freeze_backbone,\n",
    "        fine_tune_at=fine_tune_at\n",
    "    )\n",
    "\n",
    "    opt_name = trial.suggest_categorical(\"optimizer\", [\"adam\", \"adamw\"])\n",
    "    if opt_name == \"adamw\":\n",
    "        try:\n",
    "            opt = tf.keras.optimizers.AdamW(\n",
    "                learning_rate=lr,\n",
    "                weight_decay=trial.suggest_float(\"weight_decay\", 1e-6, 1e-3, log=True)\n",
    "            )\n",
    "        except Exception:\n",
    "            opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    else:\n",
    "        opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "    model.compile(optimizer=opt, loss=loss_fn, metrics=[\"accuracy\"])\n",
    "\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=7, restore_best_weights=True, verbose=0),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, min_lr=1e-7, verbose=0),\n",
    "        optuna.integration.TFKerasPruningCallback(trial, monitor=\"val_accuracy\"),\n",
    "    ]\n",
    "\n",
    "    hist = model.fit(ds_train, validation_data=ds_val, epochs=EPOCHS, callbacks=callbacks, verbose=0)\n",
    "    return float(np.max(hist.history[\"val_accuracy\"]))\n",
    "\n",
    "# =========================================\n",
    "# [5] RUN STUDY\n",
    "# =========================================\n",
    "study = optuna.create_study(direction=\"maximize\", pruner=MedianPruner(n_startup_trials=5))\n",
    "study.optimize(objective, n_trials=25, gc_after_trial=True)\n",
    "\n",
    "print(\"Best value:\", study.best_value)\n",
    "print(\"Best params:\", study.best_params)\n",
    "\n",
    "OUTDIR = Path(\"/kaggle/working/optuna_mobilenetv2\")\n",
    "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "pd.DataFrame(study.trials_dataframe()).to_csv(OUTDIR/\"trials.csv\", index=False)\n",
    "with open(OUTDIR/\"best_params.json\", \"w\") as f:\n",
    "    json.dump(study.best_params, f, indent=2)\n",
    "\n",
    "# =========================================\n",
    "# [6] RETRAIN BEST + SAVE\n",
    "# =========================================\n",
    "best = study.best_params\n",
    "bs = best[\"batch_size\"]\n",
    "\n",
    "ds_train = create_dataset(train_df, target_size=IMG_SIZE, training=True, batch_size=bs)\n",
    "ds_val   = create_dataset(val_df,   target_size=IMG_SIZE, training=False, batch_size=bs)\n",
    "\n",
    "model = build_mobilenetv2_tunable(\n",
    "    dense_units=best[\"dense_units\"],\n",
    "    dropout=best[\"dropout\"],\n",
    "    l2=best[\"l2\"],\n",
    "    freeze_backbone=best[\"freeze_backbone\"],\n",
    "    fine_tune_at=best.get(\"fine_tune_at\", None),\n",
    ")\n",
    "\n",
    "if best[\"optimizer\"] == \"adamw\":\n",
    "    try:\n",
    "        opt = tf.keras.optimizers.AdamW(learning_rate=best[\"lr\"], weight_decay=best.get(\"weight_decay\", 1e-5))\n",
    "    except Exception:\n",
    "        opt = tf.keras.optimizers.Adam(learning_rate=best[\"lr\"])\n",
    "else:\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=best[\"lr\"])\n",
    "\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "model.compile(optimizer=opt, loss=loss_fn, metrics=[\"accuracy\"])\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=7, restore_best_weights=True, verbose=1),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, min_lr=1e-7, verbose=1),\n",
    "]\n",
    "hist = model.fit(ds_train, validation_data=ds_val, epochs=EPOCHS, callbacks=callbacks, verbose=1)\n",
    "\n",
    "model.save(OUTDIR/\"best_model.keras\")\n",
    "print(\"✅ Saved:\", OUTDIR/\"best_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e8b392",
   "metadata": {
    "papermill": {
     "duration": 0.020277,
     "end_time": "2026-01-08T03:02:43.631756",
     "exception": false,
     "start_time": "2026-01-08T03:02:43.611479",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8902125,
     "sourceId": 13964761,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 290290247,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 290473834,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31240,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 717.559836,
   "end_time": "2026-01-08T03:02:47.039330",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-08T02:50:49.479494",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
